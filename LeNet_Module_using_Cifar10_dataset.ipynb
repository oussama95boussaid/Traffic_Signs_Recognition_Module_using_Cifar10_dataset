{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Load The Data** "
      ],
      "metadata": {
        "id": "1SF_-bweIojX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Load pickled data\n",
        "import pickle\n",
        "from keras.datasets import cifar10\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "VHIn8LkFAV5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fv4v32w_lP1"
      },
      "outputs": [],
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# y_train.shape is 2d, (50000, 1). While Keras is smart enough to handle this\n",
        "# it's a good idea to flatten the array.\n",
        "y_train = y_train.reshape(-1)\n",
        "y_test = y_test.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting Data**"
      ],
      "metadata": {
        "id": "qzJcbdbzIqiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify = y_train)\n",
        "n_classes = len(pd.Series(y_train).unique())"
      ],
      "metadata": {
        "id": "LBxEQatR_zOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0bYbhI6CVZd",
        "outputId": "a1933688-2d62-48a5-81a7-b4cd7eeaf2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.2.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Architecture**"
      ],
      "metadata": {
        "id": "a0kuATwYIva0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tf_slim as slim\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "St39us2mAQ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LeNet(x): \n",
        "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
        "    mu = 0\n",
        "    sigma = 0.1\n",
        "    \n",
        "    # Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6.\n",
        "    conv1_W = tf.Variable(tf.compat.v1.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
        "    conv1_b = tf.Variable(tf.zeros(6))\n",
        "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
        "    \n",
        "    # Activation 1. using relu Activation Function\n",
        "    conv1 = tf.nn.relu(conv1)\n",
        "\n",
        "    # Max Pooling. Input = 28x28x6. Output = 14x14x6.\n",
        "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "    \n",
        "    \n",
        "    # Layer 2: Convolutional. Input = 14x14x6. Output = 10x10x16.\n",
        "    conv2_W = tf.Variable(tf.compat.v1.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
        "    conv2_b = tf.Variable(tf.zeros(16))\n",
        "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
        "    \n",
        "    # Activation 2.\n",
        "    conv2 = tf.nn.relu(conv2)\n",
        "\n",
        "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
        "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "    \n",
        "    #Flatten Input : reduces the input data into a single dimension 5x5x16 = 400\n",
        "    # Flatten. Input = 5x5x16. Output = 400.\n",
        "    flattened   = slim.flatten(conv2)\n",
        "    \n",
        "    #Matrix multiplication\n",
        "    #input: 1x400\n",
        "    #weight: 400x120 \n",
        "    #Matrix multiplication(dot product rule)\n",
        "    #output = 1x400 * 400*120 => 1x120\n",
        "    \n",
        "     # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
        "    fullyc1_W = tf.Variable(tf.compat.v1.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
        "    fullyc1_b = tf.Variable(tf.zeros(120))\n",
        "    fullyc1   = tf.matmul(flattened, fullyc1_W) + fullyc1_b\n",
        "    \n",
        "    # Full connected layer activation 1.\n",
        "    fullyc1    = tf.nn.relu(fullyc1)\n",
        "    \n",
        "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
        "    fullyc2_W  = tf.Variable(tf.compat.v1.truncated_normal(shape=(120, 84), mean = 0, stddev = 0.1))\n",
        "    fullyc2_b  = tf.Variable(tf.zeros(84))\n",
        "    fullyc2    = tf.matmul(fullyc1, fullyc2_W) + fullyc2_b\n",
        "    \n",
        "    # Full connected layer activation 2.\n",
        "    fullyc2    = tf.nn.relu(fullyc2)\n",
        "    \n",
        "    # Layer 5: Fully Connected. Input = 84. Output = 43.\n",
        "    fullyc3_W  = tf.Variable(tf.compat.v1.truncated_normal(shape=(84, 43), mean = 0, stddev = 0.1))\n",
        "    fullyc3_b  = tf.Variable(tf.zeros(43))\n",
        "    logits = tf.matmul(fullyc2, fullyc3_W) + fullyc3_b\n",
        "    \n",
        "    return logits\n",
        "\n",
        "print(\"Model defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCXPbfJFCaL8",
        "outputId": "706f7f4a-2afd-42be-90f9-4b0960b953e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Features and Labels**\n",
        "x is a placeholder for a batch of input images. y is a placeholder for a batch of output labels. ."
      ],
      "metadata": {
        "id": "ktzvtn_-I3rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "y = tf.compat.v1.placeholder(tf.int64, (None))\n",
        "one_hot_y = tf.one_hot(y, n_classes)"
      ],
      "metadata": {
        "id": "A0n3KZyeCgK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"      \n",
        "Hyper parameters\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#learning rates745\n",
        "learning_rate = 0.001\n",
        "#the number of times the algorithm sees the entire data set\n",
        "epochs = 42\n",
        "#the number of samples (inputs) that will be passed through to the network at one time.\n",
        "batch_size = 128\n"
      ],
      "metadata": {
        "id": "rk6KZapJCnMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the Model**"
      ],
      "metadata": {
        "id": "TrVgJUvTJBrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = LeNet(x)\n",
        "#relation between probabilities and Erreur function CE\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits( logits=logits, labels=y)\n",
        "loss_operation = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "training_operation = optimizer.minimize(loss_operation)\n",
        "predict_operation = tf.argmax(logits, 1)\n",
        "predict_proba_operation = tf.nn.softmax(logits=logits)"
      ],
      "metadata": {
        "id": "F5GaZjgHC3d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(predict_operation, tf.argmax(one_hot_y, 1))\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "def evaluate(X_data, y_data):\n",
        "    num_examples = len(X_data)\n",
        "    total_accuracy = 0\n",
        "    total_loss = 0\n",
        "    sess = tf.compat.v1.get_default_session()\n",
        "    for offset in range(0, num_examples, batch_size):\n",
        "        batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
        "        loss, accuracy = sess.run([loss_operation, accuracy_operation], feed_dict={x: batch_x, y: batch_y})\n",
        "        total_accuracy += (accuracy * len(batch_x))\n",
        "        total_loss += (loss * len(batch_x))\n",
        "    return total_loss/num_examples, total_accuracy/num_examples\n",
        "\n",
        "print(\"Evaluate function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxSIZxK8C4Kd",
        "outputId": "20822f82-9124-469d-daf2-a9780035aaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from time import time\n",
        "import logging, datetime"
      ],
      "metadata": {
        "id": "FMskvbYAC7TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Log File for Metadata \n",
        "\"\"\"\n",
        "logger = logging.getLogger()\n",
        "#create file handler for logger\n",
        "def setup_file_logger(log_file):\n",
        "    hdlr = logging.FileHandler(log_file)\n",
        "    formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
        "    hdlr.setFormatter(formatter)\n",
        "    logger.addHandler(hdlr) \n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "def log(message):\n",
        "    #outputs to Colab console\n",
        "    print('{} {}'.format(datetime.datetime.now(), message))\n",
        "    #outputs to file\n",
        "    logger.info(message)\n",
        "\n",
        "setup_file_logger('training_Modul.log')"
      ],
      "metadata": {
        "id": "H4bjIRG9C-1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the Model**"
      ],
      "metadata": {
        "id": "yYt8EEaKI90D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_accuracy = []\n",
        "validation_loss = []\n",
        "training_accuracy = []\n",
        "training_loss = []\n",
        "saver1 = tf.compat.v1.train.Saver()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    num_examples = len(X_train)\n",
        "    \n",
        "    print(\"Start Training...\")\n",
        "    print(\"Number of epochs : {}\".format(epochs))\n",
        "    print(\"Batch size : {}\".format(batch_size))\n",
        "    print(\"Learning rate : {}\".format(learning_rate))\n",
        "    print()\n",
        "    \n",
        "\n",
        "    for i in range(epochs):\n",
        "      try:\n",
        "            X_train, y_train = shuffle(X_train, y_train)\n",
        "            for offset in range(0, num_examples, batch_size):\n",
        "                end = offset + batch_size\n",
        "                batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
        "                sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
        "                        \n",
        "            log(\"EPOCH {} ...\".format(i+1))\n",
        "            # Training data\n",
        "            train_loss, train_accuracy = evaluate(X_train, y_train)\n",
        "            training_accuracy.append(train_accuracy)\n",
        "            training_loss.append(train_loss)\n",
        "            log(\"Training Accuracy = {:.3f}\".format(train_accuracy))\n",
        "            print(\"Training error = {:.3f} \".format( train_loss ))\n",
        "            # Validation data\n",
        "            valid_loss, valid_accuracy = evaluate(X_valid, y_valid)\n",
        "            validation_accuracy.append(valid_accuracy)\n",
        "            validation_loss.append(valid_loss)\n",
        "            log(\"Validation Accuracy = {:.3f}\".format(valid_accuracy))\n",
        "            print(\"Validation error = {:.3f}\".format(valid_loss))\n",
        "            print()\n",
        "\n",
        "\n",
        "      except KeyboardInterrupt:\n",
        "          test_loss, test_accuracy = evaluate(X_valid, y_valid)\n",
        "          log('Accuracy Model On Test Images: {}'.format(test_accuracy))\n",
        "          print('Loss Model On Test Images: {}'.format(test_loss))   \n",
        "          break\n",
        "\n",
        "        \n",
        "    saver1.save(sess, 'LeNet_Modul')\n",
        "    print(\"Model saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAHcB4G-C_c8",
        "outputId": "aed0272a-a067-425c-c1ab-9a208b01b17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training...\n",
            "Number of epochs : 42\n",
            "Batch size : 128\n",
            "Learning rate : 0.001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:07:06.863009 EPOCH 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:07:18.799158 Training Accuracy = 0.290\n",
            "Training error = 1.950 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:07:23.851943 Validation Accuracy = 0.282\n",
            "Validation error = 1.976\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:07:49.692192 EPOCH 2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:08:01.690647 Training Accuracy = 0.388\n",
            "Training error = 1.657 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:08:06.965301 Validation Accuracy = 0.372\n",
            "Validation error = 1.698\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:08:32.358737 EPOCH 3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:08:45.380425 Training Accuracy = 0.434\n",
            "Training error = 1.555 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:08:50.436582 Validation Accuracy = 0.413\n",
            "Validation error = 1.625\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 4 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:09:17.474513 EPOCH 4 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:09:29.303697 Training Accuracy = 0.466\n",
            "Training error = 1.467 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:09:34.560720 Validation Accuracy = 0.435\n",
            "Validation error = 1.562\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:09:59.591343 EPOCH 5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:10:11.447130 Training Accuracy = 0.490\n",
            "Training error = 1.409 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:10:16.422984 Validation Accuracy = 0.449\n",
            "Validation error = 1.535\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 6 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:10:43.352663 EPOCH 6 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:10:55.243582 Training Accuracy = 0.521\n",
            "Training error = 1.326 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:11:00.519287 Validation Accuracy = 0.480\n",
            "Validation error = 1.477\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 7 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:11:25.952400 EPOCH 7 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:11:38.045333 Training Accuracy = 0.527\n",
            "Training error = 1.320 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:11:43.240868 Validation Accuracy = 0.470\n",
            "Validation error = 1.494\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 8 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:12:09.378389 EPOCH 8 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:12:22.415968 Training Accuracy = 0.548\n",
            "Training error = 1.260 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:12:27.561522 Validation Accuracy = 0.483\n",
            "Validation error = 1.462\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EPOCH 9 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:12:53.002203 EPOCH 9 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Training Accuracy = 0.562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:13:05.108686 Training Accuracy = 0.562\n",
            "Training error = 1.230 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Validation Accuracy = 0.488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:13:10.764279 Validation Accuracy = 0.488\n",
            "Validation error = 1.468\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Accuracy Model On Test Images: 0.49466666668256126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-03 16:13:28.543065 Accuracy Model On Test Images: 0.49466666668256126\n",
            "Loss Model On Test Images: 1.438669055366516\n",
            "Model saved\n"
          ]
        }
      ]
    }
  ]
}